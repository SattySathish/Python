{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adult Mortality</th>\n",
       "      <th>infant deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage expenditure</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>BMI</th>\n",
       "      <th>under-five deaths</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Total expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <th>thinness 5-9 years</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Schooling</th>\n",
       "      <th>Status_Developed</th>\n",
       "      <th>Status_Developing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>263.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71.279624</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1154</td>\n",
       "      <td>19.1</td>\n",
       "      <td>83</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.479</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.523582</td>\n",
       "      <td>62.0</td>\n",
       "      <td>492</td>\n",
       "      <td>18.6</td>\n",
       "      <td>86</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.476</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268.0</td>\n",
       "      <td>66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.219243</td>\n",
       "      <td>64.0</td>\n",
       "      <td>430</td>\n",
       "      <td>18.1</td>\n",
       "      <td>89</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.470</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>272.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>78.184215</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2787</td>\n",
       "      <td>17.6</td>\n",
       "      <td>93</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.52</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.097109</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3013</td>\n",
       "      <td>17.2</td>\n",
       "      <td>97</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.87</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.454</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>723.0</td>\n",
       "      <td>27</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.0</td>\n",
       "      <td>31</td>\n",
       "      <td>27.1</td>\n",
       "      <td>42</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.13</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.407</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>715.0</td>\n",
       "      <td>26</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>998</td>\n",
       "      <td>26.7</td>\n",
       "      <td>41</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.52</td>\n",
       "      <td>68.0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.418</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>73.0</td>\n",
       "      <td>25</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>304</td>\n",
       "      <td>26.3</td>\n",
       "      <td>40</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.53</td>\n",
       "      <td>71.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.427</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>686.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.0</td>\n",
       "      <td>529</td>\n",
       "      <td>25.9</td>\n",
       "      <td>39</td>\n",
       "      <td>76.0</td>\n",
       "      <td>6.16</td>\n",
       "      <td>75.0</td>\n",
       "      <td>42.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.427</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>665.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1483</td>\n",
       "      <td>25.5</td>\n",
       "      <td>39</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>78.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.434</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2083 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Adult Mortality  infant deaths  Alcohol  percentage expenditure  \\\n",
       "0               263.0             62     0.01               71.279624   \n",
       "1               271.0             64     0.01               73.523582   \n",
       "2               268.0             66     0.01               73.219243   \n",
       "3               272.0             69     0.01               78.184215   \n",
       "4               275.0             71     0.01                7.097109   \n",
       "...               ...            ...      ...                     ...   \n",
       "2933            723.0             27     4.36                0.000000   \n",
       "2934            715.0             26     4.06                0.000000   \n",
       "2935             73.0             25     4.43                0.000000   \n",
       "2936            686.0             25     1.72                0.000000   \n",
       "2937            665.0             24     1.68                0.000000   \n",
       "\n",
       "      Hepatitis B  Measles    BMI   under-five deaths   Polio  \\\n",
       "0            65.0      1154   19.1                  83    6.0   \n",
       "1            62.0       492   18.6                  86   58.0   \n",
       "2            64.0       430   18.1                  89   62.0   \n",
       "3            67.0      2787   17.6                  93   67.0   \n",
       "4            68.0      3013   17.2                  97   68.0   \n",
       "...           ...       ...    ...                 ...    ...   \n",
       "2933         68.0        31   27.1                  42   67.0   \n",
       "2934          7.0       998   26.7                  41    7.0   \n",
       "2935         73.0       304   26.3                  40   73.0   \n",
       "2936         76.0       529   25.9                  39   76.0   \n",
       "2937         79.0      1483   25.5                  39   78.0   \n",
       "\n",
       "      Total expenditure  Diphtheria    HIV/AIDS   thinness  1-19 years  \\\n",
       "0                  8.16         65.0        0.1                   17.2   \n",
       "1                  8.18         62.0        0.1                   17.5   \n",
       "2                  8.13         64.0        0.1                   17.7   \n",
       "3                  8.52         67.0        0.1                   17.9   \n",
       "4                  7.87         68.0        0.1                   18.2   \n",
       "...                 ...          ...        ...                    ...   \n",
       "2933               7.13         65.0       33.6                    9.4   \n",
       "2934               6.52         68.0       36.7                    9.8   \n",
       "2935               6.53         71.0       39.8                    1.2   \n",
       "2936               6.16         75.0       42.1                    1.6   \n",
       "2937               7.10         78.0       43.5                   11.0   \n",
       "\n",
       "       thinness 5-9 years  Income composition of resources  Schooling  \\\n",
       "0                    17.3                            0.479       10.1   \n",
       "1                    17.5                            0.476       10.0   \n",
       "2                    17.7                            0.470        9.9   \n",
       "3                    18.0                            0.463        9.8   \n",
       "4                    18.2                            0.454        9.5   \n",
       "...                   ...                              ...        ...   \n",
       "2933                  9.4                            0.407        9.2   \n",
       "2934                  9.9                            0.418        9.5   \n",
       "2935                  1.3                            0.427       10.0   \n",
       "2936                  1.7                            0.427        9.8   \n",
       "2937                 11.2                            0.434        9.8   \n",
       "\n",
       "      Status_Developed  Status_Developing  \n",
       "0                    0                  1  \n",
       "1                    0                  1  \n",
       "2                    0                  1  \n",
       "3                    0                  1  \n",
       "4                    0                  1  \n",
       "...                ...                ...  \n",
       "2933                 0                  1  \n",
       "2934                 0                  1  \n",
       "2935                 0                  1  \n",
       "2936                 0                  1  \n",
       "2937                 0                  1  \n",
       "\n",
       "[2083 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"C:/Users/Admin/Desktop/Coding/Tensorflow/lifedata.csv\")\n",
    "dataset = dataset.drop([\"Country\",\"Year\",\"GDP\", \"Population\"], axis=1).dropna()\n",
    "\n",
    "dataset = dataset.dropna(axis=0)\n",
    "label = dataset[\"Life\"]\n",
    "feature = dataset.drop(\"Life\",axis=1)\n",
    "\n",
    "# features[\"Country\"].unique()\n",
    "feature = pd.get_dummies(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14584\\1830388616.py:3: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  features = torch.tensor(features, dtype = torch.float32)\n"
     ]
    }
   ],
   "source": [
    "features = np.array(feature)\n",
    "labels = np.array(label).reshape(-1,1)\n",
    "features = torch.tensor(features, dtype = torch.float32)\n",
    "labels = torch.tensor(labels,dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(18,1)\n",
    "preds=model(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(624816.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 3.7213e+03,  8.5326e+04, -1.5542e+03, -1.3334e+06, -1.1322e+04,\n",
      "          1.2715e+07, -1.0328e+04,  1.1204e+05, -1.0886e+04, -9.9480e+02,\n",
      "         -1.0587e+04,  1.5962e+02,  1.3899e+03,  1.3856e+03, -1.1833e+02,\n",
      "         -2.2387e+03, -1.4470e+02,  5.8022e+01]])\n",
      "tensor([-86.6796])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import mse_loss\n",
    "\n",
    "loss  = mse_loss(preds, labels)\n",
    "print(loss)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(model.weight.grad)\n",
    "print(model.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(608605.2500, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-10)\n",
    "\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "preds = model(features)\n",
    "loss = mse_loss(preds, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(41740.8906, grad_fn=<MseLossBackward0>)\n",
      "tensor(12670.0225, grad_fn=<MseLossBackward0>)\n",
      "tensor(4815.4473, grad_fn=<MseLossBackward0>)\n",
      "tensor(2675.3103, grad_fn=<MseLossBackward0>)\n",
      "tensor(2074.6775, grad_fn=<MseLossBackward0>)\n",
      "tensor(1889.1570, grad_fn=<MseLossBackward0>)\n",
      "tensor(1815.9055, grad_fn=<MseLossBackward0>)\n",
      "tensor(1773.3524, grad_fn=<MseLossBackward0>)\n",
      "tensor(1739.5317, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\Coding\\Tensorflow\\life_regression.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Coding/Tensorflow/life_regression.ipynb#ch0000006?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(loss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Coding/Tensorflow/life_regression.ipynb#ch0000006?line=10'>11</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Coding/Tensorflow/life_regression.ipynb#ch0000006?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Coding/Tensorflow/life_regression.ipynb#ch0000006?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\sgd.py:146\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m             momentum_buffer_list\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmomentum_buffer\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 146\u001b[0m sgd(params_with_grad,\n\u001b[0;32m    147\u001b[0m     d_p_list,\n\u001b[0;32m    148\u001b[0m     momentum_buffer_list,\n\u001b[0;32m    149\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    150\u001b[0m     momentum\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmomentum\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    151\u001b[0m     lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    152\u001b[0m     dampening\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdampening\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    153\u001b[0m     nesterov\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mnesterov\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    154\u001b[0m     maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    155\u001b[0m     has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[0;32m    156\u001b[0m     foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    158\u001b[0m \u001b[39m# update momentum_buffers in state\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m p, momentum_buffer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\sgd.py:197\u001b[0m, in \u001b[0;36msgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_sgd\n\u001b[1;32m--> 197\u001b[0m func(params,\n\u001b[0;32m    198\u001b[0m      d_p_list,\n\u001b[0;32m    199\u001b[0m      momentum_buffer_list,\n\u001b[0;32m    200\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    201\u001b[0m      momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[0;32m    202\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    203\u001b[0m      dampening\u001b[39m=\u001b[39;49mdampening,\n\u001b[0;32m    204\u001b[0m      nesterov\u001b[39m=\u001b[39;49mnesterov,\n\u001b[0;32m    205\u001b[0m      has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[0;32m    206\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\sgd.py:241\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[0;32m    238\u001b[0m         d_p \u001b[39m=\u001b[39m buf\n\u001b[0;32m    240\u001b[0m alpha \u001b[39m=\u001b[39m lr \u001b[39mif\u001b[39;00m maximize \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39mlr\n\u001b[1;32m--> 241\u001b[0m param\u001b[39m.\u001b[39;49madd_(d_p, alpha\u001b[39m=\u001b[39;49malpha)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-10)\n",
    "\n",
    "epochs = 100000\n",
    "for epoch in range(epochs):\n",
    "    preds = model(features)\n",
    "    loss = mse_loss(preds, labels)\n",
    "    \n",
    "    if (epoch+1)%1000 == 0:\n",
    "        print(loss)\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
